*****************************************************
* Dataset Sizes
*****************************************************
Training samples: 883341
Validation samples: 110414
*****************************************************
* Best Results
*****************************************************
Best validation accuracy: 0.9741
Best Epoch: 25
Best training loss: 0.0230
Best validation loss: 0.1380

*****************************************************
* Hyperparameters
*****************************************************
lr: 0.001
batch_size: 64
epochs: 25
weight_decay: 0.03
hidden_dim: 512
embedding_dim: 128
num_layers: 2
dropout: 0.4

*****************************************************
* Best Classification Report
*****************************************************
Classification Report for Epoch 25:
                 precision    recall  f1-score   support

  GameofThrones       0.96      0.97      0.96      6308
     Historical       1.00      0.98      0.99     62908
      DoctorWho       0.93      0.96      0.95      1080
      Mythology       0.94      0.97      0.95     11984
      Offensive       0.96      0.98      0.97      4996
        Tolkien       0.94      0.95      0.94      7898
       Warcraft       0.96      0.98      0.97       728
   FinalFantasy       0.95      0.98      0.96       489
       StarWars       0.95      0.96      0.96      5767
    HarryPotter       0.92      0.94      0.93      4745
     TheWitcher       0.96      0.97      0.97       672
     DragonBall       0.90      0.97      0.93       690
         Naruto       0.95      0.98      0.97       964
ForgottenRealms       0.91      0.96      0.94       880
      Discworld       0.95      0.96      0.96       305

       accuracy                           0.97    110414
      macro avg       0.95      0.97      0.96    110414
   weighted avg       0.97      0.97      0.97    110414


*****************************************************
* SK Learn Accuracy score
*****************************************************
Best score: 0.9741


*****************************************************
* Data Configuration
*****************************************************
*****************************************************
* Data Processing Configuration
*****************************************************
path: dataset/preprocessing
output_file: dataset.txt
train_file: train.txt
dev_file: dev.txt
test_file: test.txt
config_dump: data_config.info
train_size: 0.8
dev_size: 0.1
test_size: 0.1
unique_names: True
augmentation:
  enabled: True
  only_basic_augmentation: False
  intensity: 5
  swap_characters: {'enabled': True, 'pct_words_to_swap': 0.6, 'transformations_per_example': {'min': 1, 'max': 3}}
  insert_characters: {'enabled': True, 'pct_words_to_swap': 0.6, 'transformations_per_example': {'min': 1, 'max': 3}}
  delete_characters: {'enabled': True, 'pct_words_to_swap': 0.6, 'transformations_per_example': {'min': 1, 'max': 3}}
  duplicate_characters: {'enabled': True, 'pct_words_to_swap': 0.6, 'transformations_per_example': 2}
  split_names: {'enabled': True, 'join_parts': True}
  label_exclusion: {'enabled': False, 'excluded_labels': []}
  internal_swap: {'enabled': True, 'swap_probability': 0.7}
labels: ['HarryPotter', 'StarWars', 'Tolkien', 'Warcraft', 'DragonBall', 'Naruto', 'ForgottenRealms', 'FinalFantasy', 'GameofThrones', 'TheWitcher', 'DoctorWho', 'Discworld', 'Mythology', 'Offensive', 'Historical']

Datasets:
  - Wikidata:
      name: Wikidata
      path: wikidata
      input_folder: raw_data
      output_folder: processed_data
      labels_folder: labels
      labels_file: labels.txt
      historical_file: extremely_relevant_figures2.txt
      dataset_file: wikidata-universes.csv
      output_file: wikidata_dataset_FastText.txt
  - Mythdata:
      name: Mythdata
      path: mythology
      input_folder: raw_data
      output_folder: processed_data
      dataset_file: myth_dataset.csv
      output_file: myth_dataset.txt
  - NERdata:
      name: NERdata
      path: ner
      input_folder: raw_data
      output_folder: processed_data
      output_file: ner_dataset.txt
  - Slurs:
      name: Slurs
      path: slurs
      input_folder: raw_data
      output_folder: processed_data
      dataset_file: profanity.csv
      output_file: slurs.txt


*****************************************************
* Epoch Output
*****************************************************
Epoch 1:
  Training Loss: 0.6728
  Validation Loss: 0.3653
  Validation Accuracy: 0.8041
  Learning Rate: 0.001000

Epoch 2:
  Training Loss: 0.3256
  Validation Loss: 0.2829
  Validation Accuracy: 0.8758
  Learning Rate: 0.001000

Epoch 3:
  Training Loss: 0.2744
  Validation Loss: 0.2539
  Validation Accuracy: 0.8682
  Learning Rate: 0.001000

Epoch 4:
  Training Loss: 0.2522
  Validation Loss: 0.2631
  Validation Accuracy: 0.8883
  Learning Rate: 0.001000

Epoch 5:
  Training Loss: 0.2307
  Validation Loss: 0.2157
  Validation Accuracy: 0.8975
  Learning Rate: 0.000500

Epoch 6:
  Training Loss: 0.1351
  Validation Loss: 0.1503
  Validation Accuracy: 0.9477
  Learning Rate: 0.000500

Epoch 7:
  Training Loss: 0.1112
  Validation Loss: 0.1523
  Validation Accuracy: 0.9395
  Learning Rate: 0.000500

Epoch 8:
  Training Loss: 0.1050
  Validation Loss: 0.1466
  Validation Accuracy: 0.9520
  Learning Rate: 0.000500

Epoch 9:
  Training Loss: 0.1028
  Validation Loss: 0.1442
  Validation Accuracy: 0.9509
  Learning Rate: 0.000500

Epoch 10:
  Training Loss: 0.0992
  Validation Loss: 0.1540
  Validation Accuracy: 0.9485
  Learning Rate: 0.000250

Epoch 11:
  Training Loss: 0.0664
  Validation Loss: 0.1193
  Validation Accuracy: 0.9648
  Learning Rate: 0.000250

Epoch 12:
  Training Loss: 0.0579
  Validation Loss: 0.1276
  Validation Accuracy: 0.9631
  Learning Rate: 0.000250

Epoch 13:
  Training Loss: 0.0546
  Validation Loss: 0.1254
  Validation Accuracy: 0.9645
  Learning Rate: 0.000250

Epoch 14:
  Training Loss: 0.0546
  Validation Loss: 0.1276
  Validation Accuracy: 0.9653
  Learning Rate: 0.000250

Epoch 15:
  Training Loss: 0.0526
  Validation Loss: 0.1263
  Validation Accuracy: 0.9660
  Learning Rate: 0.000125

Epoch 16:
  Training Loss: 0.0390
  Validation Loss: 0.1198
  Validation Accuracy: 0.9702
  Learning Rate: 0.000125

Epoch 17:
  Training Loss: 0.0356
  Validation Loss: 0.1225
  Validation Accuracy: 0.9717
  Learning Rate: 0.000125

Epoch 18:
  Training Loss: 0.0346
  Validation Loss: 0.1202
  Validation Accuracy: 0.9706
  Learning Rate: 0.000125

Epoch 19:
  Training Loss: 0.0337
  Validation Loss: 0.1267
  Validation Accuracy: 0.9709
  Learning Rate: 0.000125

Epoch 20:
  Training Loss: 0.0333
  Validation Loss: 0.1252
  Validation Accuracy: 0.9712
  Learning Rate: 0.000063

Epoch 21:
  Training Loss: 0.0262
  Validation Loss: 0.1266
  Validation Accuracy: 0.9739
  Learning Rate: 0.000063

Epoch 22:
  Training Loss: 0.0244
  Validation Loss: 0.1311
  Validation Accuracy: 0.9740
  Learning Rate: 0.000063

Epoch 23:
  Training Loss: 0.0237
  Validation Loss: 0.1294
  Validation Accuracy: 0.9736
  Learning Rate: 0.000063

Epoch 24:
  Training Loss: 0.0236
  Validation Loss: 0.1368
  Validation Accuracy: 0.9741
  Learning Rate: 0.000063

Epoch 25:
  Training Loss: 0.0230
  Validation Loss: 0.1380
  Validation Accuracy: 0.9741
  Learning Rate: 0.000031

*****************************************************
* Confusion Matrix
*****************************************************
[[ 6093,    14,     1,    22,    19,    76,     2,     1,    22,    47,
      2,     3,     1,     5,     0],
 [   77, 61886,    34,   401,    58,   153,     6,    15,    90,   109,
     14,    17,    17,    20,    11],
 [    2,     6,  1042,    13,     1,     4,     0,     0,     6,     1,
      0,     0,     1,     2,     2],
 [   18,    50,    25, 11576,    52,    82,     4,     2,    50,    37,
      3,    34,    20,    29,     2],
 [   12,     6,     0,    47,  4900,     9,     1,     0,     7,    10,
      0,     1,     0,     3,     0],
 [   73,    22,     4,    84,    15,  7488,    16,     3,    49,   126,
      0,     7,     2,     9,     0],
 [    4,     3,     0,     4,     0,     3,   710,     2,     1,     1,
      0,     0,     0,     0,     0],
 [    2,     2,     0,     3,     0,     0,     0,   479,     1,     2,
      0,     0,     0,     0,     0],
 [   24,    24,    11,    67,    10,    47,     1,     3,  5532,    31,
      3,     4,     3,     7,     0],
 [   47,    25,     5,    61,    19,    85,     3,     1,    42,  4447,
      0,     7,     0,     3,     0],
 [    2,     4,     1,     6,     1,     2,     0,     0,     2,     1,
    652,     0,     0,     0,     1],
 [    0,     2,     0,    10,     6,     0,     0,     0,     1,     3,
      1,   666,     1,     0,     0],
 [    0,     0,     0,    13,     1,     5,     0,     0,     2,     0,
      1,     0,   942,     0,     0],
 [    3,     5,     1,    12,     1,     5,     0,     0,     3,     4,
      0,     1,     0,   845,     0],
 [    0,     3,     1,     1,     2,     2,     0,     0,     0,     0,
      0,     1,     0,     1,   294]]

*****************************************************
* Dataset Sizes
*****************************************************
Training samples: 44620
Validation samples: 5571
*****************************************************
* Best Results
*****************************************************
Best validation accuracy: 0.6399
Best Epoch: 24
Best training loss: 0.3072
Best validation loss: 2.0661

*****************************************************
* Hyperparameters
*****************************************************
lr: 0.0005
batch_size: 32
epochs: 25
weight_decay: 0.04
hidden_dim: 256
embedding_dim: 128
num_layers: 2
dropout: 0.5

*****************************************************
* Best Classification Report
*****************************************************
Classification Report for Epoch 24:
                 precision    recall  f1-score   support

     Historical       0.95      0.65      0.78      3840
     DragonBall       0.32      0.50      0.39        18
      Mythology       0.33      0.62      0.43       497
        Tolkien       0.40      0.68      0.50       241
       StarWars       0.31      0.50      0.38       236
    HarryPotter       0.30      0.51      0.38       158
      Offensive       0.65      0.83      0.73       206
      DoctorWho       0.27      0.60      0.37        58
  GameofThrones       0.38      0.61      0.47       154
     TheWitcher       0.21      0.48      0.29        21
ForgottenRealms       0.30      0.43      0.35        47
         Naruto       0.38      0.71      0.49        31
      Discworld       0.25      0.41      0.31        17
   FinalFantasy       0.16      0.29      0.21        24
       Warcraft       0.23      0.30      0.26        23

       accuracy                           0.64      5571
      macro avg       0.36      0.54      0.42      5571
   weighted avg       0.77      0.64      0.68      5571


*****************************************************
* SK Learn Accuracy score
*****************************************************
Best score: 0.6399


*****************************************************
* Data Configuration
*****************************************************
*****************************************************
* Data Processing Configuration
*****************************************************
path: dataset/preprocessing
output_file: dataset.txt
train_file: train.txt
dev_file: dev.txt
test_file: test.txt
config_dump: data_config.info
train_size: 0.8
dev_size: 0.1
test_size: 0.1
unique_names: True
augmentation:
  enabled: True
  only_basic_augmentation: True
  intensity: 3
  swap_characters: {'enabled': True, 'pct_words_to_swap': 0.6, 'transformations_per_example': {'min': 1, 'max': 5}}
  insert_characters: {'enabled': True, 'pct_words_to_swap': 0.6, 'transformations_per_example': {'min': 1, 'max': 5}}
  delete_characters: {'enabled': True, 'pct_words_to_swap': 0.6, 'transformations_per_example': {'min': 1, 'max': 4}}
  duplicate_characters: {'enabled': True, 'pct_words_to_swap': 0.6, 'transformations_per_example': 3}
  split_names: {'enabled': True, 'join_parts': True}
  label_exclusion: {'enabled': False, 'excluded_labels': []}
  internal_swap: {'enabled': True, 'swap_probability': 0.7}
labels: ['HarryPotter', 'StarWars', 'Tolkien', 'Warcraft', 'DragonBall', 'Naruto', 'ForgottenRealms', 'FinalFantasy', 'GameofThrones', 'TheWitcher', 'DoctorWho', 'Discworld', 'Mythology', 'Offensive', 'Historical']

Datasets:
  - Wikidata:
      name: Wikidata
      path: wikidata
      input_folder: raw_data
      output_folder: processed_data
      labels_folder: labels
      labels_file: labels.txt
      historical_file: extremely_relevant_figures2.txt
      dataset_file: wikidata-universes.csv
      output_file: wikidata_dataset_FastText.txt
  - Mythdata:
      name: Mythdata
      path: mythology
      input_folder: raw_data
      output_folder: processed_data
      dataset_file: myth_dataset.csv
      output_file: myth_dataset.txt
  - NERdata:
      name: NERdata
      path: ner
      input_folder: raw_data
      output_folder: processed_data
      output_file: ner_dataset.txt
  - Slurs:
      name: Slurs
      path: slurs
      input_folder: raw_data
      output_folder: processed_data
      dataset_file: profanity.csv
      output_file: slurs.txt


*****************************************************
* Epoch Output
*****************************************************
Epoch 1:
  Training Loss: 2.3557
  Validation Loss: 2.1342
  Validation Accuracy: 0.2795
  Learning Rate: 0.000500

Epoch 2:
  Training Loss: 1.9990
  Validation Loss: 1.9250
  Validation Accuracy: 0.3087
  Learning Rate: 0.000500

Epoch 3:
  Training Loss: 1.6976
  Validation Loss: 1.8098
  Validation Accuracy: 0.3678
  Learning Rate: 0.000500

Epoch 4:
  Training Loss: 1.4462
  Validation Loss: 1.7124
  Validation Accuracy: 0.4150
  Learning Rate: 0.000500

Epoch 5:
  Training Loss: 1.2613
  Validation Loss: 1.6712
  Validation Accuracy: 0.4701
  Learning Rate: 0.000250

Epoch 6:
  Training Loss: 0.9964
  Validation Loss: 1.5985
  Validation Accuracy: 0.4938
  Learning Rate: 0.000250

Epoch 7:
  Training Loss: 0.8847
  Validation Loss: 1.6011
  Validation Accuracy: 0.5004
  Learning Rate: 0.000250

Epoch 8:
  Training Loss: 0.7886
  Validation Loss: 1.6416
  Validation Accuracy: 0.5313
  Learning Rate: 0.000250

Epoch 9:
  Training Loss: 0.7220
  Validation Loss: 1.7126
  Validation Accuracy: 0.5459
  Learning Rate: 0.000250

Epoch 10:
  Training Loss: 0.6707
  Validation Loss: 1.7091
  Validation Accuracy: 0.5114
  Learning Rate: 0.000125

Epoch 11:
  Training Loss: 0.5904
  Validation Loss: 1.6911
  Validation Accuracy: 0.5843
  Learning Rate: 0.000125

Epoch 12:
  Training Loss: 0.5273
  Validation Loss: 1.7418
  Validation Accuracy: 0.5814
  Learning Rate: 0.000125

Epoch 13:
  Training Loss: 0.5042
  Validation Loss: 1.7690
  Validation Accuracy: 0.5864
  Learning Rate: 0.000125

Epoch 14:
  Training Loss: 0.4755
  Validation Loss: 1.8263
  Validation Accuracy: 0.5821
  Learning Rate: 0.000125

Epoch 15:
  Training Loss: 0.4539
  Validation Loss: 1.8043
  Validation Accuracy: 0.5959
  Learning Rate: 0.000063

Epoch 16:
  Training Loss: 0.4083
  Validation Loss: 1.8873
  Validation Accuracy: 0.6015
  Learning Rate: 0.000063

Epoch 17:
  Training Loss: 0.3903
  Validation Loss: 1.8673
  Validation Accuracy: 0.6058
  Learning Rate: 0.000063

Epoch 18:
  Training Loss: 0.3738
  Validation Loss: 1.9147
  Validation Accuracy: 0.6125
  Learning Rate: 0.000063

Epoch 19:
  Training Loss: 0.3665
  Validation Loss: 1.9302
  Validation Accuracy: 0.6123
  Learning Rate: 0.000063

Epoch 20:
  Training Loss: 0.3558
  Validation Loss: 1.9546
  Validation Accuracy: 0.6198
  Learning Rate: 0.000031

Epoch 21:
  Training Loss: 0.3318
  Validation Loss: 1.9891
  Validation Accuracy: 0.6279
  Learning Rate: 0.000031

Epoch 22:
  Training Loss: 0.3257
  Validation Loss: 1.9889
  Validation Accuracy: 0.6277
  Learning Rate: 0.000031

Epoch 23:
  Training Loss: 0.3166
  Validation Loss: 2.0207
  Validation Accuracy: 0.6344
  Learning Rate: 0.000031

Epoch 24:
  Training Loss: 0.3072
  Validation Loss: 2.0661
  Validation Accuracy: 0.6399
  Learning Rate: 0.000031

Epoch 25:
  Training Loss: 0.3006
  Validation Loss: 2.0654
  Validation Accuracy: 0.6392
  Learning Rate: 0.000016

*****************************************************
* Confusion Matrix
*****************************************************
[[2514,   12,  483,  154,  183,  144,   61,   65,   88,   30,   27,   23,
    16,   21,   19],
 [   1,    9,    2,    0,    1,    0,    1,    0,    1,    0,    0,    2,
     0,    1,    0],
 [  45,    4,  306,   32,   47,   16,    9,    4,    9,    2,    6,    8,
     2,    5,    2],
 [  15,    1,   15,  163,    5,    6,    2,    3,   25,    1,    4,    0,
     0,    1,    0],
 [  17,    1,   43,   15,  118,    9,    4,    7,   12,    1,    2,    2,
     0,    3,    2],
 [  19,    0,   12,   13,    5,   81,    9,    4,    6,    1,    4,    0,
     1,    3,    0],
 [   3,    1,   10,    4,    1,    4,  172,    4,    4,    0,    0,    0,
     2,    1,    0],
 [   8,    0,    4,    2,    3,    0,    3,   35,    1,    0,    0,    1,
     0,    0,    1],
 [   9,    0,   10,   15,   11,    6,    2,    4,   94,    1,    2,    0,
     0,    0,    0],
 [   1,    0,    4,    0,    2,    2,    0,    0,    0,   10,    1,    0,
     0,    1,    0],
 [   5,    0,    8,    7,    1,    0,    2,    1,    3,    0,   20,    0,
     0,    0,    0],
 [   1,    0,    8,    0,    0,    0,    0,    0,    0,    0,    0,   22,
     0,    0,    0],
 [   0,    0,    4,    2,    0,    2,    0,    1,    0,    1,    0,    0,
     7,    0,    0],
 [   5,    0,    5,    2,    2,    1,    0,    0,    1,    1,    0,    0,
     0,    7,    0],
 [   2,    0,    2,    2,    5,    1,    0,    1,    3,    0,    0,    0,
     0,    0,    7]]

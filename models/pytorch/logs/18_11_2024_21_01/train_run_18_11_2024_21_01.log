*****************************************************
* Dataset Sizes
*****************************************************
Training samples: 477546
Validation samples: 59689
*****************************************************
* Best Results
*****************************************************
Best validation accuracy: 0.9639
Best Epoch: 16
Best training loss: 0.0461
Best validation loss: 0.1195

*****************************************************
* Hyperparameters
*****************************************************
lr: 0.001
batch_size: 32
epochs: 30
weight_decay: 0.03
hidden_dim: 512
embedding_dim: 128
num_layers: 2
dropout: 0.5

*****************************************************
* Best Classification Report
*****************************************************
Classification Report for Epoch 16:
                 precision    recall  f1-score   support

     Historical       0.99      0.98      0.98     33828
       StarWars       0.95      0.94      0.94      3187
        Tolkien       0.91      0.95      0.93      4237
  GameofThrones       0.94      0.96      0.95      3378
    HarryPotter       0.92      0.91      0.91      2575
      Mythology       0.92      0.94      0.93      6599
      Discworld       0.97      0.95      0.96       165
      Offensive       0.96      0.96      0.96      2702
ForgottenRealms       0.95      0.89      0.92       480
      DoctorWho       0.97      0.92      0.95       590
     DragonBall       0.91      0.94      0.92       391
       Warcraft       0.97      0.93      0.95       391
         Naruto       0.97      0.93      0.95       532
   FinalFantasy       0.95      0.92      0.94       271
     TheWitcher       0.98      0.94      0.96       363

       accuracy                           0.96     59689
      macro avg       0.95      0.94      0.94     59689
   weighted avg       0.96      0.96      0.96     59689


*****************************************************
* SK Learn Accuracy score
*****************************************************
Best score: 0.9639


*****************************************************
* Data Configuration
*****************************************************
*****************************************************
* Data Processing Configuration
*****************************************************
path: dataset/preprocessing
output_file: dataset.txt
train_file: train.txt
dev_file: dev.txt
test_file: test.txt
config_dump: data_config.info
train_size: 0.8
dev_size: 0.1
test_size: 0.1
unique_names: True
augmentation:
  enabled: True
  intensity: 2
  swap_characters: {'enabled': True, 'pct_words_to_swap': 0.5, 'transformations_per_example': {'min': 1, 'max': 4}}
  insert_characters: {'enabled': True, 'pct_words_to_swap': 0.6, 'transformations_per_example': {'min': 1, 'max': 4}}
  delete_characters: {'enabled': True, 'pct_words_to_swap': 0.5, 'transformations_per_example': {'min': 1, 'max': 4}}
  duplicate_characters: {'enabled': True, 'pct_words_to_swap': 0.4, 'transformations_per_example': 1}
  split_names: {'enabled': True, 'join_parts': True}
  label_exclusion: {'enabled': True, 'excluded_labels': []}
  internal_swap: {'enabled': True, 'swap_probability': 0.6}
labels: ['HarryPotter', 'StarWars', 'Tolkien', 'Warcraft', 'DragonBall', 'Naruto', 'ForgottenRealms', 'FinalFantasy', 'GameofThrones', 'TheWitcher', 'DoctorWho', 'Discworld', 'Mythology', 'Offensive', 'Historical']

Datasets:
  - Wikidata:
      name: Wikidata
      path: wikidata
      input_folder: raw_data
      output_folder: processed_data
      labels_folder: labels
      labels_file: labels.txt
      historical_file: extremely_relevant_figures2.txt
      dataset_file: wikidata-universes.csv
      output_file: wikidata_dataset_FastText.txt
  - Mythdata:
      name: Mythdata
      path: mythology
      input_folder: raw_data
      output_folder: processed_data
      dataset_file: myth_dataset.csv
      output_file: myth_dataset.txt
  - NERdata:
      name: NERdata
      path: ner
      input_folder: raw_data
      output_folder: processed_data
      output_file: ner_dataset.txt
  - Slurs:
      name: Slurs
      path: slurs
      input_folder: raw_data
      output_folder: processed_data
      dataset_file: profanity.csv
      output_file: slurs.txt


*****************************************************
* Epoch Output
*****************************************************
Epoch 1:
  Training Loss: 0.5136
  Validation Loss: 0.2976
  Validation Accuracy: 0.9016
  Learning Rate: 0.001000

Epoch 2:
  Training Loss: 0.2924
  Validation Loss: 0.2445
  Validation Accuracy: 0.9192
  Learning Rate: 0.001000

Epoch 3:
  Training Loss: 0.2474
  Validation Loss: 0.2266
  Validation Accuracy: 0.9254
  Learning Rate: 0.001000

Epoch 4:
  Training Loss: 0.2254
  Validation Loss: 0.2045
  Validation Accuracy: 0.9332
  Learning Rate: 0.001000

Epoch 5:
  Training Loss: 0.2111
  Validation Loss: 0.2042
  Validation Accuracy: 0.9334
  Learning Rate: 0.000500

Epoch 6:
  Training Loss: 0.1365
  Validation Loss: 0.1421
  Validation Accuracy: 0.9544
  Learning Rate: 0.000500

Epoch 7:
  Training Loss: 0.1202
  Validation Loss: 0.1452
  Validation Accuracy: 0.9551
  Learning Rate: 0.000500

Epoch 8:
  Training Loss: 0.1148
  Validation Loss: 0.1428
  Validation Accuracy: 0.9549
  Learning Rate: 0.000500

Epoch 9:
  Training Loss: 0.1108
  Validation Loss: 0.1411
  Validation Accuracy: 0.9547
  Learning Rate: 0.000500

Epoch 10:
  Training Loss: 0.1086
  Validation Loss: 0.1493
  Validation Accuracy: 0.9536
  Learning Rate: 0.000250

Epoch 11:
  Training Loss: 0.0757
  Validation Loss: 0.1206
  Validation Accuracy: 0.9618
  Learning Rate: 0.000250

Epoch 12:
  Training Loss: 0.0674
  Validation Loss: 0.1276
  Validation Accuracy: 0.9609
  Learning Rate: 0.000250

Epoch 13:
  Training Loss: 0.0647
  Validation Loss: 0.1257
  Validation Accuracy: 0.9611
  Learning Rate: 0.000250

Epoch 14:
  Training Loss: 0.0632
  Validation Loss: 0.1237
  Validation Accuracy: 0.9616
  Learning Rate: 0.000250

Epoch 15:
  Training Loss: 0.0629
  Validation Loss: 0.1318
  Validation Accuracy: 0.9598
  Learning Rate: 0.000125

Epoch 16:
  Training Loss: 0.0461
  Validation Loss: 0.1195
  Validation Accuracy: 0.9639
  Learning Rate: 0.000125

Epoch 17:
  Training Loss: 0.0423
  Validation Loss: 0.1223
  Validation Accuracy: 0.9633
  Learning Rate: 0.000125

Epoch 18:
  Training Loss: 0.0409
  Validation Loss: 0.1247
  Validation Accuracy: 0.9628
  Learning Rate: 0.000125

Epoch 19:
  Training Loss: 0.0401
  Validation Loss: 0.1297
  Validation Accuracy: 0.9613
  Learning Rate: 0.000125

Epoch 20:
  Training Loss: 0.0398
  Validation Loss: 0.1269
  Validation Accuracy: 0.9623
  Learning Rate: 0.000063

Epoch 21:
  Training Loss: 0.0315
  Validation Loss: 0.1250
  Validation Accuracy: 0.9638
  Learning Rate: 0.000063

Epoch 22:
  Training Loss: 0.0299
  Validation Loss: 0.1274
  Validation Accuracy: 0.9632
  Learning Rate: 0.000063

Epoch 23:
  Training Loss: 0.0293
  Validation Loss: 0.1293
  Validation Accuracy: 0.9635
  Learning Rate: 0.000063

Epoch 24:
  Training Loss: 0.0286
  Validation Loss: 0.1310
  Validation Accuracy: 0.9626
  Learning Rate: 0.000063

Epoch 25:
  Training Loss: 0.0280
  Validation Loss: 0.1297
  Validation Accuracy: 0.9625
  Learning Rate: 0.000031

Epoch 26:
  Training Loss: 0.0240
  Validation Loss: 0.1311
  Validation Accuracy: 0.9630
  Learning Rate: 0.000031

Epoch 27:
  Training Loss: 0.0231
  Validation Loss: 0.1341
  Validation Accuracy: 0.9630
  Learning Rate: 0.000031

Epoch 28:
  Training Loss: 0.0228
  Validation Loss: 0.1357
  Validation Accuracy: 0.9633
  Learning Rate: 0.000031

Epoch 29:
  Training Loss: 0.0225
  Validation Loss: 0.1331
  Validation Accuracy: 0.9633
  Learning Rate: 0.000031

Epoch 30:
  Training Loss: 0.0221
  Validation Loss: 0.1382
  Validation Accuracy: 0.9625
  Learning Rate: 0.000016


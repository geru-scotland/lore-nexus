*****************************************************
* Dataset Sizes
*****************************************************
Training samples: 656772
Validation samples: 82091
*****************************************************
* Best Results
*****************************************************
Best validation accuracy: 0.9576
Best Epoch: 24
Best training loss: 0.0451
Best validation loss: 0.1951

*****************************************************
* Hyperparameters
*****************************************************
lr: 0.0005
batch_size: 64
epochs: 25
weight_decay: 0.03
hidden_dim: 256
embedding_dim: 128
num_layers: 3
dropout: 0.5

*****************************************************
* Best Classification Report
*****************************************************
Classification Report for Epoch 24:
                 precision    recall  f1-score   support

      Discworld       0.90      0.94      0.92       223
         Naruto       0.92      0.96      0.94       698
     Historical       1.00      0.96      0.98     47200
      DoctorWho       0.85      0.96      0.90       802
       StarWars       0.92      0.95      0.93      4209
        Tolkien       0.92      0.94      0.93      5811
      Offensive       0.94      0.97      0.96      3699
      Mythology       0.89      0.94      0.92      8888
  GameofThrones       0.94      0.96      0.95      4583
    HarryPotter       0.87      0.94      0.90      3441
   FinalFantasy       0.89      0.96      0.92       361
ForgottenRealms       0.84      0.96      0.89       658
     TheWitcher       0.93      0.98      0.96       486
     DragonBall       0.82      0.97      0.89       500
       Warcraft       0.91      0.97      0.94       532

       accuracy                           0.96     82091
      macro avg       0.90      0.96      0.93     82091
   weighted avg       0.96      0.96      0.96     82091


*****************************************************
* SK Learn Accuracy score
*****************************************************
Best score: 0.9576


*****************************************************
* Data Configuration
*****************************************************
*****************************************************
* Data Processing Configuration
*****************************************************
path: dataset/preprocessing
output_file: dataset.txt
train_file: train.txt
dev_file: dev.txt
test_file: test.txt
config_dump: data_config.info
train_size: 0.8
dev_size: 0.1
test_size: 0.1
unique_names: True
augmentation:
  enabled: True
  only_basic_augmentation: False
  intensity: 3
  swap_characters: {'enabled': True, 'pct_words_to_swap': 0.6, 'transformations_per_example': {'min': 1, 'max': 5}}
  insert_characters: {'enabled': True, 'pct_words_to_swap': 0.6, 'transformations_per_example': {'min': 1, 'max': 5}}
  delete_characters: {'enabled': True, 'pct_words_to_swap': 0.6, 'transformations_per_example': {'min': 1, 'max': 4}}
  duplicate_characters: {'enabled': True, 'pct_words_to_swap': 0.6, 'transformations_per_example': 3}
  split_names: {'enabled': True, 'join_parts': True}
  label_exclusion: {'enabled': False, 'excluded_labels': []}
  internal_swap: {'enabled': True, 'swap_probability': 0.7}
labels: ['HarryPotter', 'StarWars', 'Tolkien', 'Warcraft', 'DragonBall', 'Naruto', 'ForgottenRealms', 'FinalFantasy', 'GameofThrones', 'TheWitcher', 'DoctorWho', 'Discworld', 'Mythology', 'Offensive', 'Historical']

Datasets:
  - Wikidata:
      name: Wikidata
      path: wikidata
      input_folder: raw_data
      output_folder: processed_data
      labels_folder: labels
      labels_file: labels.txt
      historical_file: extremely_relevant_figures2.txt
      dataset_file: wikidata-universes.csv
      output_file: wikidata_dataset_FastText.txt
  - Mythdata:
      name: Mythdata
      path: mythology
      input_folder: raw_data
      output_folder: processed_data
      dataset_file: myth_dataset.csv
      output_file: myth_dataset.txt
  - NERdata:
      name: NERdata
      path: ner
      input_folder: raw_data
      output_folder: processed_data
      output_file: ner_dataset.txt
  - Slurs:
      name: Slurs
      path: slurs
      input_folder: raw_data
      output_folder: processed_data
      dataset_file: profanity.csv
      output_file: slurs.txt


*****************************************************
* Epoch Output
*****************************************************
Epoch 1:
  Training Loss: 1.0553
  Validation Loss: 0.5559
  Validation Accuracy: 0.7096
  Learning Rate: 0.000500

Epoch 2:
  Training Loss: 0.5069
  Validation Loss: 0.3930
  Validation Accuracy: 0.7945
  Learning Rate: 0.000500

Epoch 3:
  Training Loss: 0.3867
  Validation Loss: 0.3355
  Validation Accuracy: 0.8070
  Learning Rate: 0.000500

Epoch 4:
  Training Loss: 0.3263
  Validation Loss: 0.2842
  Validation Accuracy: 0.8531
  Learning Rate: 0.000500

Epoch 5:
  Training Loss: 0.2907
  Validation Loss: 0.2669
  Validation Accuracy: 0.8557
  Learning Rate: 0.000250

Epoch 6:
  Training Loss: 0.1969
  Validation Loss: 0.2089
  Validation Accuracy: 0.9032
  Learning Rate: 0.000250

Epoch 7:
  Training Loss: 0.1674
  Validation Loss: 0.2003
  Validation Accuracy: 0.9035
  Learning Rate: 0.000250

Epoch 8:
  Training Loss: 0.1574
  Validation Loss: 0.1962
  Validation Accuracy: 0.9183
  Learning Rate: 0.000250

Epoch 9:
  Training Loss: 0.1467
  Validation Loss: 0.1912
  Validation Accuracy: 0.9225
  Learning Rate: 0.000250

Epoch 10:
  Training Loss: 0.1435
  Validation Loss: 0.1997
  Validation Accuracy: 0.9139
  Learning Rate: 0.000125

Epoch 11:
  Training Loss: 0.1068
  Validation Loss: 0.1746
  Validation Accuracy: 0.9426
  Learning Rate: 0.000125

Epoch 12:
  Training Loss: 0.0967
  Validation Loss: 0.1756
  Validation Accuracy: 0.9425
  Learning Rate: 0.000125

Epoch 13:
  Training Loss: 0.0906
  Validation Loss: 0.1793
  Validation Accuracy: 0.9440
  Learning Rate: 0.000125

Epoch 14:
  Training Loss: 0.0882
  Validation Loss: 0.1778
  Validation Accuracy: 0.9454
  Learning Rate: 0.000125

Epoch 15:
  Training Loss: 0.0849
  Validation Loss: 0.1805
  Validation Accuracy: 0.9463
  Learning Rate: 0.000063

Epoch 16:
  Training Loss: 0.0685
  Validation Loss: 0.1780
  Validation Accuracy: 0.9502
  Learning Rate: 0.000063

Epoch 17:
  Training Loss: 0.0637
  Validation Loss: 0.1742
  Validation Accuracy: 0.9519
  Learning Rate: 0.000063

Epoch 18:
  Training Loss: 0.0607
  Validation Loss: 0.1853
  Validation Accuracy: 0.9513
  Learning Rate: 0.000063

Epoch 19:
  Training Loss: 0.0603
  Validation Loss: 0.1816
  Validation Accuracy: 0.9522
  Learning Rate: 0.000063

Epoch 20:
  Training Loss: 0.0569
  Validation Loss: 0.1836
  Validation Accuracy: 0.9530
  Learning Rate: 0.000031

Epoch 21:
  Training Loss: 0.0499
  Validation Loss: 0.1888
  Validation Accuracy: 0.9562
  Learning Rate: 0.000031

Epoch 22:
  Training Loss: 0.0478
  Validation Loss: 0.1933
  Validation Accuracy: 0.9570
  Learning Rate: 0.000031

Epoch 23:
  Training Loss: 0.0465
  Validation Loss: 0.1950
  Validation Accuracy: 0.9566
  Learning Rate: 0.000031

Epoch 24:
  Training Loss: 0.0451
  Validation Loss: 0.1951
  Validation Accuracy: 0.9576
  Learning Rate: 0.000031

Epoch 25:
  Training Loss: 0.0442
  Validation Loss: 0.2003
  Validation Accuracy: 0.9569
  Learning Rate: 0.000016

*****************************************************
* Confusion Matrix
*****************************************************
[[  210,     0,     0,     3,     1,     0,     1,     3,     0,     1,
      1,     0,     2,     0,     1],
 [    0,   673,     1,     1,     3,     0,     1,    14,     0,     2,
      0,     0,     0,     2,     1],
 [   14,    25, 45454,    79,   158,   217,   100,   693,   132,   197,
     19,    48,    15,    29,    20],
 [    0,     1,     3,   770,     2,     4,     1,    14,     2,     3,
      0,     0,     1,     0,     1],
 [    3,     1,    12,     9,  3985,    32,     9,    70,    21,    35,
      4,     8,     5,     9,     6],
 [    2,     1,     9,     4,    46,  5460,    18,    72,    58,   103,
      3,    10,     2,     8,    15],
 [    1,     1,     4,     1,    12,    13,  3599,    28,     9,    22,
      0,     1,     1,     4,     3],
 [    2,    27,    20,    22,    60,    93,    68,  8399,    29,    73,
     11,    36,     5,    38,     5],
 [    1,     1,     6,     5,    18,    58,    10,    39,  4380,    46,
      2,     9,     2,     4,     2],
 [    1,     1,     8,    11,    30,    63,    14,    40,    26,  3230,
      2,     8,     0,     7,     0],
 [    0,     0,     1,     0,     1,     2,     0,     5,     3,     1,
    346,     1,     1,     0,     0],
 [    0,     0,     0,     2,     9,     4,     0,     6,     4,     2,
      0,   630,     0,     1,     0],
 [    0,     0,     1,     0,     0,     3,     0,     3,     1,     0,
      0,     0,   477,     1,     0],
 [    0,     2,     1,     1,     3,     3,     1,     4,     2,     0,
      0,     0,     0,   483,     0],
 [    0,     0,     0,     0,     2,     3,     0,     7,     1,     0,
      0,     2,     1,     0,   516]]
